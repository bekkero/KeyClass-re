activation: torch.nn.LeakyReLU()
average: weighted
base_encoder: bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12
criterion: torch.nn.CrossEntropyLoss(reduction='none')
data_path: C:\Users\joshb\PycharmProjects\KeyClass-main\scripts\data\
dataset: mimic
device: cuda
end_model_batch_size: 128
end_model_epochs: 20
end_model_lr: 1e-4
end_model_patience: 3
end_model_weight_decay: 1e-4
h_sizes:
- 768
- 256
- 64
- 6
label_model: data_programming
label_model_lr: 0.01
label_model_n_epochs: 100
max_num: 500
min_df: 0.001
model_path: C:\Users\joshb\PycharmProjects\KeyClass-re\models\mimic
n_bootstrap: 100
n_classes: 6
n_jobs: 10
ngram_range: !!python/tuple
- 1
- 3
normalize_embeddings: false
preds_path: C:\Users\joshb\PycharmProjects\KeyClass-re\results\mimic\
q_update_interval: 50
results_path: C:\Users\joshb\PycharmProjects\KeyClass-re\results\mimic\
self_train_batch_size: 8
self_train_lr: 1e-6
self_train_patience: 8
self_train_thresh: 1-2e-3
self_train_weight_decay: 1e-4
show_progress_bar: true
target_0: 0
target_1: 1
target_2: 2
target_3: 3
target_4: 4
target_5: 5
topk: 35
use_custom_encoder: true
use_noise_aware_loss: true
